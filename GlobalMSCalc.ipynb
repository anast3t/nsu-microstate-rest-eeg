{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Расчет общих микросостояний на основе всех имеющихся",
   "id": "b824b202c8e2f8d9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.332603Z",
     "start_time": "2024-05-09T08:18:46.865429Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from helper import *\n",
    "from filenames_and_paths import *\n",
    "\n",
    "from neurokit2.stats.cluster import cluster\n",
    "import scipy\n",
    "import numpy as np\n",
    "import sklearn\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.338410Z",
     "start_time": "2024-05-09T08:18:47.332603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _microstates_segment_runsegmentation(data, microstates, gfp, n_microstates):\n",
    "    # Find microstate corresponding to each datapoint\n",
    "    activation = microstates.dot(data)\n",
    "    segmentation = np.argmax(np.abs(activation), axis=0)\n",
    "    polarity = np.sign(np.choose(segmentation, activation))\n",
    "\n",
    "    # Get Global Explained Variance (GEV)\n",
    "    gev, gev_all = _cluster_quality_gev(\n",
    "        data.T, microstates, segmentation, sd=gfp, n_clusters=n_microstates\n",
    "    )\n",
    "    return segmentation, polarity, gev, gev_all\n",
    "\n",
    "def _cluster_quality_gev(data, clusters, clustering, sd=None, n_clusters=4):\n",
    "    \"\"\"Global Variance Explained (GEV)\"\"\"\n",
    "    if sd is None:\n",
    "        sd = np.nanstd(data, axis=1)\n",
    "    map_corr = _correlate_vectors(data.T, clusters[clustering].T)\n",
    "\n",
    "    gev_all = np.zeros(n_clusters)\n",
    "    for state in range(n_clusters):\n",
    "        idx = clustering == state\n",
    "        gev_all[state] = np.nansum((sd[idx] * map_corr[idx]) ** 2) / np.nansum(sd**2)\n",
    "\n",
    "    gev = np.nansum(gev_all)\n",
    "    #    gev = np.sum((sd * map_corr) ** 2) / np.sum(sd**2)\n",
    "    return gev, gev_all\n",
    "\n",
    "\n",
    "def _correlate_vectors(A, B, axis=0):\n",
    "    \"\"\"Compute pairwise correlation of multiple pairs of vectors.\n",
    "    Fast way to compute correlation of multiple pairs of vectors without\n",
    "    computing all pairs as would with corr(A,B). Borrowed from Oli at Stack\n",
    "    overflow.\n",
    "\n",
    "    Note the resulting coefficients vary slightly from the ones\n",
    "    obtained from corr due differences in the order of the calculations.\n",
    "    (Differences are of a magnitude of 1e-9 to 1e-17 depending of the tested\n",
    "    data).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array\n",
    "        The first collection of vectors of shape (n, m)\n",
    "    B : array\n",
    "        The second collection of vectors of shape (n, m)\n",
    "    axis : int\n",
    "        The axis that contains the elements of each vector. Defaults to 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr : array\n",
    "        For each pair of vectors, the correlation between them with shape (m, )\n",
    "\n",
    "    \"\"\"\n",
    "    An = A - np.nanmean(A, axis=axis)\n",
    "    Bn = B - np.nanmean(B, axis=axis)\n",
    "    An /= np.linalg.norm(An, axis=axis)\n",
    "    Bn /= np.linalg.norm(Bn, axis=axis)\n",
    "    return np.nansum(An * Bn, axis=axis)"
   ],
   "id": "b8ee8fd89ea053d0",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.344752Z",
     "start_time": "2024-05-09T08:18:47.339413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_data_folder_path = \"./raw_data/\"\n",
    "preprocessed_data_folder_path = \"./preprocessed_data/\"\n",
    "save_data_folder_path = \"./save_data/\"\n",
    "images_folder_path = \"./images/\"\n",
    "statistics_folder_path = \"statistics/\"\n",
    "mhw_objects_folder_path = \"mhw_objects/\"\n",
    "\n",
    "folders = Folders(\n",
    "    end_folder = \"\",\n",
    "    raw_data = raw_data_folder_path,\n",
    "    preprocessed_data = preprocessed_data_folder_path,\n",
    "    save_data = save_data_folder_path,\n",
    "    images = images_folder_path,\n",
    "    statistics=statistics_folder_path,\n",
    "    mhw_objects=mhw_objects_folder_path\n",
    ")\n",
    "\n",
    "\n",
    "filenames014 = [\n",
    "    \"ACP_INP0014_REST1_1pnt_1vis\",\n",
    "    \"ACP_INP0014_REST2_1pnt_1vis\",\n",
    "    \"ACP_INP0014_REST3_1pnt_1vis\",\n",
    "    \"ACP_INP0014_REST1_1pnt_2vis\",\n",
    "    \"ACP_INP0014_REST2_1pnt_2vis\",\n",
    "    \"ACP_INP0014_REST3_1pnt_2vis\"\n",
    "]\n",
    "path014 = \"rest_14/\"\n",
    "\n",
    "filenames019 = [\n",
    "    \"INP0019_v1.4_REST1_R003_R003_08.11.23\",\n",
    "    \"INP0019_v1.4_REST2_R003_R003_08.11.23\",\n",
    "    \"INP0019_v1.4_REST3_R003_R003_08.11.23\",\n",
    "    \"INP0019_v1.5_REST2_Op005_Op007_08.12.23\",\n",
    "    \"INP0019_v1.5_REST3_Op005_Op007_08.12.23\",\n",
    "]\n",
    "path019 = \"rest_19/\"\n",
    "\n",
    "filenames036 = [\n",
    "    \"INP0036_v1.4_REST1_Op008_Op011_11.12.23\",\n",
    "    \"INP0036_v1.4_REST2_Op008_Op011_11.12.23\",\n",
    "    \"INP0036_v1.4_REST3_Op008_Op011_11.12.23\",\n",
    "    \"INP0036_v1.5_REST1_Op005_Op010_12.12.23\",\n",
    "    \"INP0036_v1.5_REST2_Op005_Op010_12.12.23\",\n",
    "    \"INP0036_v1.5_REST3_Op005_Op010_12.12.23\",\n",
    "]\n",
    "path036 = \"rest_36/\"\n",
    "\n",
    "filenames045 = [\n",
    "    \"INP0045_v1.4_REST1_R003_R003_08.11.23\",\n",
    "    \"INP0045_v1.4_REST2_R003_R003_08.11.23\",\n",
    "    \"INP0045_v1.4_REST3_R003_R003_08.11.23\",\n",
    "    \"INP0045_v1.5_rs11_Op005_Op008_Op011_17.11.23\",\n",
    "    \"INP0045_v1.5_rs22_Op005_Op008_Op011_17.11.23\",\n",
    "    \"INP0045_v1.5_rs23_Op005_Op008_Op011_17.11.23\",\n",
    "]\n",
    "path045 = \"rest_45/\"\n",
    "\n",
    "filenames064 = [\n",
    "    \"INP0064_v1.4_rs11_S008_R003_04.12.23\",\n",
    "    \"INP0064_v1.4_rs12_Op008_R003_04.12.23\",\n",
    "    \"INP0064_v1.4_rs13_Op008_R003_04.12.23\",\n",
    "    \"INP0064_v1.5_rs21_Op005_Op006_Op008_05.12.23\",\n",
    "    \"INP0064_v1.5_rs22_Op009_A002_13.12.23\",\n",
    "    \"INP0064_v1.5_rs23_Op009_A002_13.12.23\",\n",
    "]\n",
    "path064 = \"rest_64/\"\n",
    "\n",
    "filenames = [filenames014, filenames019, filenames036, filenames045, filenames064]\n",
    "paths = [path014, path019, path036, path045, path064]"
   ],
   "id": "64c541b079577ad8",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.350478Z",
     "start_time": "2024-05-09T08:18:47.344752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ms_df = pd.DataFrame()\n",
    "mhw = None"
   ],
   "id": "963307a24dc15e50",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.369450Z",
     "start_time": "2024-05-09T08:18:47.350478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for i in range(len(filenames)):\n",
    "# # for i in range(1):\n",
    "#     for filename in filenames[i]:\n",
    "#         path = paths[i]\n",
    "#         folders.end_folder = path\n",
    "#         th_filename = filename + \"_th\"\n",
    "#         print(f\"Processing {filename}\")\n",
    "#         raw = mne.io.read_raw_eeglab(folders.preprocessed_data + folders.end_folder + filename + '.set')\n",
    "#         mhw = MicrostateHelperWrapper(folders, raw, th_filename)\n",
    "#         mhw = mhw.load()\n",
    "#         ms_df = pd.concat([ms_df, pd.DataFrame.from_records(mhw.ms['Microstates'])])\n",
    "ms_df = pd.read_csv(folders.save_data + \"global_ms_df.csv\")\n",
    "# ms_df = ms_df.drop([0, 1, 2, 3], axis=0)\n",
    "ms_df"
   ],
   "id": "4f78edaaeeaf41f3",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.371955Z",
     "start_time": "2024-05-09T08:18:47.369450Z"
    }
   },
   "cell_type": "code",
   "source": "# ms_df.reset_index(drop=True, inplace=True)",
   "id": "68e41003caaa20e2",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.377675Z",
     "start_time": "2024-05-09T08:18:47.371955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# replace NaN with 0\n",
    "# ms_df.fillna(0, inplace=True)"
   ],
   "id": "555622ccfcfdfb0b",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.382886Z",
     "start_time": "2024-05-09T08:18:47.378679Z"
    }
   },
   "cell_type": "code",
   "source": "# ms_df.to_csv(folders.save_data + \"global_ms_df.csv\", index=False)",
   "id": "447ad7d509b7dcaf",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.387993Z",
     "start_time": "2024-05-09T08:18:47.382886Z"
    }
   },
   "cell_type": "code",
   "source": "# clustering, clusters, cluster_info = cluster(ms_df, n_clusters=4, method='kmod', verbose=True)",
   "id": "e251c28d1776689e",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.393496Z",
     "start_time": "2024-05-09T08:18:47.387993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for i in range(4):\n",
    "#     mne.viz.plot_topomap(clusters[i], mhw.raw.info, show=True)\n"
   ],
   "id": "42ed44033e7a0d29",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.399256Z",
     "start_time": "2024-05-09T08:18:47.393496Z"
    }
   },
   "cell_type": "code",
   "source": "# _cluster_quality_gev(ms_df, clusters, clustering[\"Cluster\"])",
   "id": "e67d1347aace641a",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.402396Z",
     "start_time": "2024-05-09T08:18:47.400259Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a4ca6e7f62505806",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.405953Z",
     "start_time": "2024-05-09T08:18:47.402396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "methods = [\n",
    "    \"kmod\",\n",
    "    \"kmeans\",\n",
    "    \"kmedoids\",\n",
    "    \"pca\",\n",
    "    \"ica\",\n",
    "    \"aahc\",\n",
    "    \"hierarchical\",\n",
    "    \"spectral\",\n",
    "    \"mixture\",\n",
    "    \"mixturebayesian\"\n",
    "]\n",
    "# method_df = pd.DataFrame(columns=methods)\n",
    "# for i in range(100):\n",
    "#     print(i)\n",
    "#     val_arr = []\n",
    "#     for method in methods:\n",
    "#         clustering, clusters, cluster_info = cluster(ms_df, n_clusters=4, method=method)\n",
    "#         print(\"===============\" + method + \"===================\")\n",
    "#         # for i in range(4):\n",
    "#         #     mne.viz.plot_topomap(clusters[i], mhw.raw.info, show=True)\n",
    "#         quality = _cluster_quality_gev(ms_df, clusters, clustering[\"Cluster\"])\n",
    "#         print(quality)\n",
    "#         val_arr.append(quality[0])\n",
    "#     method_df = pd.concat([method_df, pd.DataFrame([val_arr], columns=methods)])\n",
    "\n",
    "# cols2 = [\"GEV\", \"GEV1\", \"GEV2\", \"GEV3\", \"GEV4\", \"Method\"]\n",
    "# method_df2 = pd.DataFrame(columns=cols2)\n",
    "# for i in range(100):\n",
    "#     print(i)\n",
    "#     val_arr = []\n",
    "#     for method in methods:\n",
    "#         clustering, clusters, cluster_info = cluster(ms_df, n_clusters=4, method=method)\n",
    "#         print(\"===============\" + method + \"===================\")\n",
    "#         # for i in range(4):\n",
    "#         #     mne.viz.plot_topomap(clusters[i], mhw.raw.info, show=True)\n",
    "#         quality = _cluster_quality_gev(ms_df, clusters, clustering[\"Cluster\"])\n",
    "#         print(quality)\n",
    "#         sorted_quality = np.sort(quality[1])\n",
    "#         val_arr.append([quality[0], *sorted_quality, method])\n",
    "#     method_df2 = pd.concat([method_df2, pd.DataFrame(val_arr, columns=cols2)])\n"
   ],
   "id": "129359ff19e5a0de",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.411459Z",
     "start_time": "2024-05-09T08:18:47.406956Z"
    }
   },
   "cell_type": "code",
   "source": "# method_df*100",
   "id": "be5a81d4ed6b1cc3",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:47.416881Z",
     "start_time": "2024-05-09T08:18:47.411968Z"
    }
   },
   "cell_type": "code",
   "source": "# method_df2.groupby(\"Method\").mean()*100",
   "id": "a9bc5aae9894a3c4",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Сравнение методов для исходных данных",
   "id": "a76e39520222ea8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.079250Z",
     "start_time": "2024-05-09T08:18:47.416881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw = mne.io.read_raw_eeglab(folders.preprocessed_data + path014 + filenames[0][0] + '.set')\n",
    "raw.load_data(verbose=False)"
   ],
   "id": "730893b32704c22d",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.082356Z",
     "start_time": "2024-05-09T08:18:49.080255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# method_df = pd.DataFrame(columns=methods)"
   ],
   "id": "f26c1a439635c6b1",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.088682Z",
     "start_time": "2024-05-09T08:18:49.082356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# methods = [\n",
    "#     \"kmod\",\n",
    "#     \"kmeans\",\n",
    "#     # \"kmedoids\",\n",
    "#     # \"pca\",\n",
    "#     # \"ica\",\n",
    "#     \"aahc\",\n",
    "#     \"hierarchical\",\n",
    "#     \"spectral\",\n",
    "#     # \"mixture\",\n",
    "#     # \"mixturebayesian\"\n",
    "# ]\n",
    "# for i in range(100):\n",
    "#     print(i)\n",
    "#     val_arr = []\n",
    "#     for method in methods:\n",
    "#         clustering, clusters, cluster_info = cluster(ms_df, n_clusters=4, method=method)\n",
    "#         print(\"===============\" + method + \"===================\")\n",
    "#         # for i in range(4):\n",
    "#         #     mne.viz.plot_topomap(clusters[i], mhw.raw.info, show=True)\n",
    "#         quality = _cluster_quality_gev(ms_df, clusters, clustering[\"Cluster\"])\n",
    "#         print(quality)\n",
    "#         val_arr.append(quality[0])\n",
    "#     method_df = pd.concat([method_df, pd.DataFrame([val_arr], columns=methods)])\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(i)\n",
    "\n",
    "# ms_arr = {\n",
    "#     \"kmod\": [],\n",
    "#     \"kmeans\": [],\n",
    "#     # \"kmedoids\": [],\n",
    "#     # \"pca\": [],\n",
    "#     # \"ica\": [],\n",
    "#     \"aahc\": [],\n",
    "#     \"hierarchical\": [],\n",
    "#     \"spectral\": [],\n",
    "#     # \"mixture\": [],\n",
    "#     # \"mixturebayesian\": []\n",
    "# }\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(i)\n",
    "#     val_arr = []\n",
    "#     for method in methods:\n",
    "#         print(\"===============\" + method + \"===================\")\n",
    "#         microstates = nk.microstates_segment(raw, n_microstates=4, method=method)\n",
    "#         print(microstates[\"GEV\"])\n",
    "#         val_arr.append(microstates[\"GEV\"])\n",
    "#         ms_arr[method].append(microstates)\n",
    "#     method_df = pd.concat([method_df, pd.DataFrame([val_arr], columns=methods)])\n",
    "        "
   ],
   "id": "d65f1dac3684728e",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.094150Z",
     "start_time": "2024-05-09T08:18:49.088682Z"
    }
   },
   "cell_type": "code",
   "source": "# method_df",
   "id": "89ecd666c2bc2f40",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.100009Z",
     "start_time": "2024-05-09T08:18:49.094150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# for (key, value) in ms_arr.items():\n",
    "#     print(key)\n",
    "#     fig, axes = plt.subplots(len(value), 4, figsize=(10, 10))\n",
    "#     fig.suptitle(key)\n",
    "#     for i in range(len(value)):\n",
    "#         for j in range(4):\n",
    "#             mne.viz.plot_topomap(value[i][\"Microstates\"][j], value[i][\"Info\"], show=False, axes=axes[i][j])\n",
    "#     plt.show()"
   ],
   "id": "763681e54b0c44bd",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.105143Z",
     "start_time": "2024-05-09T08:18:49.100009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Gev per microstate into df\n",
    "# cols = [\"GEV1\", \"GEV2\", \"GEV3\", \"GEV4\", \"Method\"]\n",
    "# gev_per_ms = pd.DataFrame(columns=cols)\n",
    "# for (key, value) in ms_arr.items():\n",
    "#     for i in range(len(value)):\n",
    "#         # row = [*value[i][\"GEV_per_microstate\"], key]\n",
    "#         # print(pd.DataFrame.from_records(row))\n",
    "#         gev_per_ms = pd.concat([gev_per_ms, pd.DataFrame([[*np.sort(value[i][\"GEV_per_microstate\"]), key]], columns=cols)])"
   ],
   "id": "bbfca3208d4553e5",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.110185Z",
     "start_time": "2024-05-09T08:18:49.105143Z"
    }
   },
   "cell_type": "code",
   "source": "# gev_per_ms.groupby(\"Method\").mean()*100",
   "id": "1913c987d73899db",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.115560Z",
     "start_time": "2024-05-09T08:18:49.110185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ms_arr to pickle \n",
    "# import pickle\n",
    "# with open(folders.save_data + \"ms_arr.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(ms_arr, f)\n"
   ],
   "id": "2f5896c83fd9ee46",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.120534Z",
     "start_time": "2024-05-09T08:18:49.115560Z"
    }
   },
   "cell_type": "code",
   "source": "# cluster_quality = nk.cluster_quality(ms_df, clustering, clusters, cluster_info)",
   "id": "8e0fb0a1d3fb034d",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.125916Z",
     "start_time": "2024-05-09T08:18:49.120534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# scipy.spatial.distance.cdist(mhw.ms[\"Microstates\"], clusters, 'correlation')\n",
    "# 2 0 3 2"
   ],
   "id": "900bf24d23b61046",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.131422Z",
     "start_time": "2024-05-09T08:18:49.125916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# scipy.spatial.distance.cdist(mhw.ms[\"Microstates\"], clusters, 'euclidean')\n",
    "# 2 1 3 3"
   ],
   "id": "1ef04d38a1c86caf",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.137874Z",
     "start_time": "2024-05-09T08:18:49.131929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import functools\n",
    "from neurokit2.stats.cluster_quality import _cluster_quality_distance\n",
    "from neurokit2.stats.cluster import _cluster_getclusters\n",
    "import warnings\n",
    "from neurokit2 import check_random_state\n",
    "\n",
    "\n",
    "def _cluster_kmod(\n",
    "        data,\n",
    "        n_clusters=4,\n",
    "        max_iterations=1000,\n",
    "        threshold=1e-6,\n",
    "        random_state=None,\n",
    "        optimize=False,\n",
    "        **kwargs\n",
    "):\n",
    "\n",
    "    n_samples, n_channels = data.shape\n",
    "\n",
    "    # Cache this value for later to compute residual\n",
    "    data_sum_sq = np.sum(data**2)\n",
    "\n",
    "    # Select random timepoints for our initial topographic maps\n",
    "    rng = check_random_state(random_state)\n",
    "    init_times = rng.choice(n_samples, size=n_clusters, replace=False)\n",
    "\n",
    "    # Initialize random cluster centroids\n",
    "    clusters = data[init_times, :]\n",
    "\n",
    "    # Normalize row-wise (across EEG channels)\n",
    "    clusters /= np.linalg.norm(clusters, axis=1, keepdims=True)  # Normalize the maps\n",
    "\n",
    "    # Initialize iteration\n",
    "    prev_residual = 0\n",
    "    for i in range(max_iterations):\n",
    "\n",
    "        # Step 3: Assign each sample to the best matching microstate\n",
    "        activation = clusters.dot(data.T)\n",
    "        segmentation = np.argmax(np.abs(activation), axis=0)\n",
    "        # print(activation[:4],segmentation[:4])\n",
    "        # Step 4: Recompute the topographic maps of the microstates, based on the\n",
    "        # samples that were assigned to each state.\n",
    "        for state in np.arange(n_clusters):\n",
    "\n",
    "            # Get data fro specific state\n",
    "            idx = segmentation == state\n",
    "            data_state = data[idx, :]\n",
    "\n",
    "            # Sanity check\n",
    "            if np.sum(idx) == 0:\n",
    "                clusters[state] = 0\n",
    "                continue\n",
    "\n",
    "            # Retrieve map values\n",
    "\n",
    "            if optimize:\n",
    "                # Method 2 - optimized segmentation\n",
    "                state_vals = data_state.T.dot(activation[state, idx])\n",
    "            else:\n",
    "                # Method 1 - eighen value\n",
    "                # step 4a\n",
    "                Sk = np.dot(data_state.T, data_state)\n",
    "                # step 4b\n",
    "                eigen_vals, eigen_vectors = scipy.linalg.eigh(Sk)\n",
    "                state_vals = eigen_vectors[:, np.argmax(np.abs(eigen_vals))]\n",
    "\n",
    "            state_vals /= np.linalg.norm(state_vals)  # Normalize Map\n",
    "            clusters[state, :] = state_vals  # Store map\n",
    "\n",
    "        # Estimate residual noise (step 5)\n",
    "        act_sum_sq = np.sum(np.sum(clusters[segmentation, :] * data, axis=1) ** 2)\n",
    "        residual = np.abs(data_sum_sq - act_sum_sq)\n",
    "        residual = residual / float(n_samples * (n_channels - 1))\n",
    "\n",
    "        # Have we converged? Convergence criterion: variance estimate (step 6)\n",
    "        if np.abs(prev_residual - residual) < (threshold * residual):\n",
    "            break\n",
    "\n",
    "        # Next iteration\n",
    "        prev_residual = residual.copy()\n",
    "\n",
    "    if i == max_iterations:\n",
    "        warnings.warn(\n",
    "            \"Modified K-means algorithm failed to converge after \" + str(i) + \"\",\n",
    "            \"iterations. Consider increasing 'max_iterations'.\",\n",
    "        )\n",
    "\n",
    "    # De-normalize\n",
    "    clusters_unnormalized = _cluster_getclusters(data, segmentation)\n",
    "    prediction = _cluster_quality_distance(data, clusters_unnormalized, to_dataframe=True)\n",
    "    prediction[\"Cluster\"] = segmentation\n",
    "\n",
    "    # Copy function with given parameters\n",
    "    clustering_function = functools.partial(\n",
    "        _cluster_kmod,\n",
    "        n_clusters=n_clusters,\n",
    "        max_iterations=max_iterations,\n",
    "        threshold=threshold,\n",
    "        random_state=random_state,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # Info dump\n",
    "    info = {\n",
    "        \"n_clusters\": n_clusters,\n",
    "        \"clustering_function\": clustering_function,\n",
    "        \"random_state\": random_state,\n",
    "        \"clusters_normalized\": clusters,\n",
    "        \"residual\": residual,\n",
    "    }\n",
    "\n",
    "    return prediction, clusters_unnormalized, info"
   ],
   "id": "f4638671eb622e4f",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.143713Z",
     "start_time": "2024-05-09T08:18:49.137874Z"
    }
   },
   "cell_type": "code",
   "source": "# clustering1, clusters1, cluster_info1 = _cluster_kmod(ms_df.values, n_clusters=4, method='kmod', verbose=True)",
   "id": "e24191cc2772a412",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.148790Z",
     "start_time": "2024-05-09T08:18:49.143713Z"
    }
   },
   "cell_type": "code",
   "source": "# np.bincount(clustering1['Cluster'])",
   "id": "d9895134dc86d0f0",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:49.153790Z",
     "start_time": "2024-05-09T08:18:49.148790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for i in range(4):\n",
    "#     mne.viz.plot_topomap(clusters1[i], mhw.raw.info, show=True)"
   ],
   "id": "4881bc9bd20fad00",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:49:03.622720Z",
     "start_time": "2024-05-09T08:49:03.597193Z"
    }
   },
   "cell_type": "code",
   "source": "clustering2, clusters2, cluster_info2 = cluster(ms_df.values, n_clusters=4, method='kmean', verbose=True)",
   "id": "75fe2b80f1c0975e",
   "execution_count": 113,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:49:04.599864Z",
     "start_time": "2024-05-09T08:49:04.377855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(4):\n",
    "    mne.viz.plot_topomap(clusters2[i], raw.info, show=True)"
   ],
   "id": "1ef00ad9c7b725fa",
   "execution_count": 114,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:49:18.023653Z",
     "start_time": "2024-05-09T08:49:17.884684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(clustering2.drop(columns=[\"Cluster\"])[4*3:].head(12))"
   ],
   "id": "39390c0c898ae5e5",
   "execution_count": 115,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:49:44.071207Z",
     "start_time": "2024-05-09T08:49:43.885506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "global_maps = pd.DataFrame(clusters2.T, columns=[\"C\", \"D\", \"A\", \"B\"])\n",
    "global_maps = global_maps.reindex([\"A\", \"B\", \"C\", \"D\"], axis=1)\n",
    "# global_maps\n",
    "for i in range(4):\n",
    "    mne.viz.plot_topomap(global_maps.T.to_numpy()[i], raw.info, show=True)"
   ],
   "id": "6039b81b8a2e0893",
   "execution_count": 116,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:36:20.303825Z",
     "start_time": "2024-05-09T09:36:20.293812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_global_maps = global_maps.T\n",
    "t_global_maps.columns = raw.ch_names\n",
    "t_global_maps.T"
   ],
   "id": "654382bf2f2e6a27",
   "execution_count": 121,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:38:54.601604Z",
     "start_time": "2024-05-09T09:38:54.593787Z"
    }
   },
   "cell_type": "code",
   "source": "t_global_maps",
   "id": "2ef1387540389924",
   "execution_count": 123,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:36:22.216094Z",
     "start_time": "2024-05-09T09:36:22.212221Z"
    }
   },
   "cell_type": "code",
   "source": "t_global_maps.to_csv(folders.save_data + \"global_maps.csv\", index=True)",
   "id": "d2debfb2878925ac",
   "execution_count": 122,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.397712Z",
     "start_time": "2024-05-09T08:18:50.383245Z"
    }
   },
   "cell_type": "code",
   "source": "clustering_user, clusters_user, cluster_info_user = cluster(ms_df[:12].values, n_clusters=4, method='kmean', verbose=True)",
   "id": "daaf94ca7f0351a1",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.404829Z",
     "start_time": "2024-05-09T08:18:50.397712Z"
    }
   },
   "cell_type": "code",
   "source": "clustering_user",
   "id": "4ec1667085d2fdaf",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.620024Z",
     "start_time": "2024-05-09T08:18:50.405834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(4):\n",
    "    mne.viz.plot_topomap(clusters_user[i], raw.info, show=True)"
   ],
   "id": "5981f7c1fa1b32b6",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.623487Z",
     "start_time": "2024-05-09T08:18:50.620024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(np.argmin(scipy.spatial.distance.cdist(clusters_user, global_maps.T), axis=1))\n",
    "arr = scipy.spatial.distance.cdist(clusters_user, global_maps.T)\n",
    "arr"
   ],
   "id": "4602ff0577a48677",
   "execution_count": 39,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.634356Z",
     "start_time": "2024-05-09T08:18:50.623487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arr = scipy.spatial.distance.cdist(clusters_user, global_maps.T)\n",
    "arr_buf = arr.copy()\n",
    "# arr.min()\n",
    "remap_df = pd.DataFrame(columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\"])\n",
    "\n",
    "labels = {\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\"\n",
    "}\n",
    "\n",
    "for i in range(4):\n",
    "    index = np.argwhere(arr_buf == np.min(arr_buf))\n",
    "    data_index = index[0][0]\n",
    "    label_index = index[0][1]\n",
    "    remap_df = pd.concat([remap_df, pd.DataFrame(\n",
    "        [[arr[data_index, 0], arr[data_index, 1], arr[data_index, 2], arr[data_index, 3], labels[label_index]]],\n",
    "        columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\"],\n",
    "        index=[data_index]\n",
    "    )])\n",
    "    arr_buf[data_index, :] = np.inf\n",
    "    arr_buf[:, label_index] = np.inf\n",
    "    \n",
    "remap_df.sort_index(inplace=True)"
   ],
   "id": "84517023642acc3f",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.639936Z",
     "start_time": "2024-05-09T08:18:50.634356Z"
    }
   },
   "cell_type": "code",
   "source": "remap_df",
   "id": "192613308d81cc44",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.646534Z",
     "start_time": "2024-05-09T08:18:50.639936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arr = scipy.spatial.distance.cdist(clusters_user, global_maps.T)\n",
    "arr_buf = arr.copy()\n",
    "# arr.min()\n",
    "remap_df = pd.DataFrame(columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\"])\n",
    "labels = {\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\"\n",
    "}\n",
    "\n",
    "remapper = {\n",
    "}\n",
    "\n",
    "for i in range(4):\n",
    "    index = np.argwhere(arr_buf.T[i] == np.min(arr_buf.T[i]))[0][0]\n",
    "    if index in remapper:\n",
    "        assigned_label = remapper[index]\n",
    "        next_nearest_curr_ms_val = arr_buf[index].take([i, assigned_label])\n",
    "        next_nearest_conflicting_ms_val = arr_buf[remapper[index]].take([i, assigned_label])\n",
    "        print(next_nearest_curr_ms_val, next_nearest_conflicting_ms_val)\n",
    "    remapper[index] = i\n",
    "\n",
    "\n",
    "\n",
    "    # prev = arr_buf[index][remapper[index]]\n",
    "    # curr = arr_buf[index][i]   \n",
    "    #     if(curr < prev):\n",
    "    #         conflicting_val = remap_df.loc[remap_df[\"label\"] == labels[remapper[index]]]\n",
    "    #         print(conflicting_val)\n",
    "    #         arr_buf[index][remapper[index]] = np.inf\n",
    "    #         index = np.argwhere(arr_buf.T[i] == np.min(arr_buf.T[i]))[0][0]\n",
    "    #     arr_buf.T[i][index] = np.inf\n",
    "    #     index = np.argwhere(arr_buf.T[i] == np.min(arr_buf.T[i]))[0][0]\n",
    "    # remap_df = pd.concat([remap_df, pd.DataFrame([[arr[index, 0], arr[index, 1], arr[index, 2], arr[index, 3], labels[i]]], columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\"], index=[index])])"
   ],
   "id": "5c56a9dcd8a7ace2",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ПЕРЕСТАНОВКАМИ",
   "id": "bdcb10ca0f647e00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.652039Z",
     "start_time": "2024-05-09T08:18:50.646534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_regroup_variants(available: [int], max_len=4, current_len=0):\n",
    "    # print(current_len, max_len)\n",
    "    if len(available) == 1:\n",
    "        return available\n",
    "    variants = []\n",
    "    current_len += 1\n",
    "    if current_len == max_len:\n",
    "        return available\n",
    "    for num in available:\n",
    "        available_copy = available.copy()\n",
    "        available_copy.remove(num)\n",
    "        if num < max_len and num+max_len in available_copy:\n",
    "            available_copy.remove(num+max_len)\n",
    "        elif num >= max_len and num-max_len in available_copy:\n",
    "            available_copy.remove(num-max_len)\n",
    "        # print(available_copy)\n",
    "        for variant in calc_regroup_variants(available_copy, max_len=max_len, current_len=current_len):\n",
    "            if isinstance(variant, int):\n",
    "                variants.append([num, variant])\n",
    "            else:\n",
    "                variants.append([num, *variant])\n",
    "    return variants"
   ],
   "id": "6b08da2d227dcb23",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.657722Z",
     "start_time": "2024-05-09T08:18:50.652039Z"
    }
   },
   "cell_type": "code",
   "source": "calc_regroup_variants([0, 1, 2, 3], max_len=2)",
   "id": "708a76f23cb08d8c",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.667549Z",
     "start_time": "2024-05-09T08:18:50.657722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import reduce\n",
    "\n",
    "remap_df = pd.DataFrame(columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\"])\n",
    "remap_df_inv = pd.DataFrame(columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\", \"inv\"])\n",
    "labels = {\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\"\n",
    "}\n",
    "# unique_regroup_variants = {}\n",
    "inverted_clusters_user = clusters_user * -1\n",
    "clusters_user_and_inv = np.append(clusters_user, inverted_clusters_user, axis=0)\n",
    "# print(clusters_user_and_inv.shape)\n",
    "distances = scipy.spatial.distance.cdist(clusters_user_and_inv, global_maps.T)\n",
    "# distances\n",
    "min_combination = []\n",
    "min_distance = np.inf\n",
    "min_nums = []\n",
    "for variant in (calc_regroup_variants([0, 1, 2, 3, 4, 5, 6, 7], max_len=4)):\n",
    "    # print(variant)\n",
    "    dist = 0\n",
    "    # print(distances)\n",
    "    for i in range(4):\n",
    "        # print(distances.T[i, variant[i]])\n",
    "        dist += distances.T[i, variant[i]]\n",
    "    # print(distances.take(variant).sum())\n",
    "    # dist = distances.take(variant).sum()\n",
    "    if dist < min_distance:\n",
    "        min_distance = dist\n",
    "        min_combination = variant\n",
    "        min_nums = [distances.T[i, variant[i]] for i in range(4)]\n",
    "print(\"##########\")\n",
    "print(min_combination)\n",
    "print(min_nums)\n",
    "print(min_distance)\n",
    "print(distances)\n",
    "\n",
    "\n",
    "for enum_idx, i in enumerate(min_combination):\n",
    "    print(enum_idx, i)\n",
    "    # label = (labels[i] if i < 4 else labels[i-4]) if i in min_combination else \"\"\n",
    "    real_idx = i if i < 4 else i-4\n",
    "    remap_df_inv = pd.concat([remap_df_inv, pd.DataFrame([[distances.T[0, i], distances.T[1, i], distances.T[2, i], distances.T[3, i], labels[enum_idx], i>=4]], columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\", \"inv\"], index=[real_idx])])\n",
    "    # remap_df_inv = pd.concat([remap_df_inv, pd.DataFrame([[distances[i+4, 0], distances[i+4, 1], distances[i+4, 2], distances[i+4, 3], labels[min_combination[i]], True]], columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\", \"inv\"], index=[i+4])])\n",
    "\n",
    "\n",
    "    # unique_regroup_variants[tuple(variant)] += distances.take(variant)\n",
    "\n",
    "# unique_regroup_variants\n",
    "                                \n",
    "# \n",
    "# print(unique_regroup_variants)\n",
    "# for variant in unique_regroup_variants:\n",
    "#     for i in range(4):\n",
    "#         unique_regroup_variants[variant] += distances[i, variant[i]]\n",
    "\n",
    "# print(unique_regroup_variants)\n",
    "# \n",
    "# minimal = min(unique_regroup_variants, key=unique_regroup_variants.get)\n",
    "# \n",
    "# for i in range(4):\n",
    "#     remap_df = pd.concat([remap_df, pd.DataFrame([[distances[i, 0], distances[i, 1], distances[i, 2], distances[i, 3], labels[minimal[i]]]], columns=[\"Distance_A\", \"Distance_B\", \"Distance_C\", \"Distance_D\", \"label\"], index=[i])])\n",
    "\n",
    "\n",
    "#[0.94127511 0.47770597 1.36711743 0.31876249]"
   ],
   "id": "2369bd4055c05c63",
   "execution_count": 45,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.673664Z",
     "start_time": "2024-05-09T08:18:50.667549Z"
    }
   },
   "cell_type": "code",
   "source": "remap_df_inv.sort_index()",
   "id": "21291f4450c299e7",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.675575Z",
     "start_time": "2024-05-09T08:18:50.673664Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "36783d834e1142b5",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:50.861808Z",
     "start_time": "2024-05-09T08:18:50.675575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(4):\n",
    "    mne.viz.plot_topomap(global_maps[labels[i]].T, raw.info, show=True)"
   ],
   "id": "42a8ea817823c7e2",
   "execution_count": 47,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.060128Z",
     "start_time": "2024-05-09T08:18:50.861808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(4):\n",
    "    mne.viz.plot_topomap(clusters_user[i], raw.info, show=True)"
   ],
   "id": "1bbe81ebcacad43a",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.278861Z",
     "start_time": "2024-05-09T08:18:51.060128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(4):\n",
    "    mne.viz.plot_topomap(clusters_user[i]*-1, raw.info, show=True)"
   ],
   "id": "3eba40beba8859ad",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.284672Z",
     "start_time": "2024-05-09T08:18:51.279806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "remap_df.sort_index(inplace=True)\n",
    "remap_df"
   ],
   "id": "560d6e77bfc64bfd",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.398805Z",
     "start_time": "2024-05-09T08:18:51.284672Z"
    }
   },
   "cell_type": "code",
   "source": "sns.heatmap(scipy.spatial.distance.cdist(clusters_user, global_maps.T, 'correlation'))",
   "id": "5f58427ccb084ea0",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.630614Z",
     "start_time": "2024-05-09T08:18:51.398805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(4):\n",
    "    mne.viz.plot_topomap(clusters_user[i], raw.info, show=True)"
   ],
   "id": "7efc753a7e1ec4ad",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.749768Z",
     "start_time": "2024-05-09T08:18:51.630614Z"
    }
   },
   "cell_type": "code",
   "source": "sns.heatmap(scipy.spatial.distance.cdist(ms_df[:4], clusters2, 'correlation'))",
   "id": "e872d73d1d5e07e2",
   "execution_count": 53,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.753130Z",
     "start_time": "2024-05-09T08:18:51.750772Z"
    }
   },
   "cell_type": "code",
   "source": "# kmeans = sklearn.cluster.KMeans(n_clusters=4, max_iter=100000, tol=1e-9).fit(ms_df.values)",
   "id": "aa92507c9d7cf5ce",
   "execution_count": 54,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.758747Z",
     "start_time": "2024-05-09T08:18:51.753130Z"
    }
   },
   "cell_type": "code",
   "source": "# np.bincount(kmeans.labels_)",
   "id": "943755c64d7e954c",
   "execution_count": 55,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.767042Z",
     "start_time": "2024-05-09T08:18:51.758747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for i in range(4):\n",
    "#     mne.viz.plot_topomap(kmeans.cluster_centers_[i], mhw.raw.info, show=True)"
   ],
   "id": "6bb4ef323476d945",
   "execution_count": 56,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.776479Z",
     "start_time": "2024-05-09T08:18:51.771548Z"
    }
   },
   "cell_type": "code",
   "source": "# kmeans2 = sklearn.cluster.BisectingKMeans(n_clusters=4, init='k-means++').fit(ms_df.values)",
   "id": "7989dacba3efe1ac",
   "execution_count": 57,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.781484Z",
     "start_time": "2024-05-09T08:18:51.776479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pd.DataFrame.from_records([kmeans2.labels_]).T\n",
    "# np.bincount(kmeans2.labels_)"
   ],
   "id": "5d81c4ab8db88b42",
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.786699Z",
     "start_time": "2024-05-09T08:18:51.781986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for i in range(4):\n",
    "#     mne.viz.plot_topomap(kmeans2.cluster_centers_[i], mhw.raw.info, show=True)"
   ],
   "id": "ef1e46a1f133bd72",
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.791702Z",
     "start_time": "2024-05-09T08:18:51.786699Z"
    }
   },
   "cell_type": "code",
   "source": "# centroid, label = scipy.cluster.vq.kmeans2(ms_df.values, 4, minit='++', iter=1000)",
   "id": "8032c63f3353021f",
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:18:51.795703Z",
     "start_time": "2024-05-09T08:18:51.793212Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c497a95fd36e6a6c",
   "execution_count": 60,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
