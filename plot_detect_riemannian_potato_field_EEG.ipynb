{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n# Online Artifact Detection with Riemannian Potato Field\n\nExample of Riemannian Potato Field (RPF) [1]_ applied on EEG time-series to\ndetect artifacts in online processing. It is compared to the Riemannian Potato\n(RP) [2]_.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T21:57:15.047805Z",
     "start_time": "2024-05-29T21:57:14.761002Z"
    }
   },
   "source": [
    "# Authors: Quentin Barthélemy\n#\n# License: BSD (3-clause)\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.animation import FuncAnimation\n\nfrom mne.datasets import eegbci\nfrom mne.io import read_raw_edf\nfrom mne.channels import make_standard_montage\nfrom mne import make_fixed_length_epochs\n\nfrom pyriemann.estimation import Covariances\nfrom pyriemann.utils.covariance import normalize\nfrom pyriemann.clustering import Potato, PotatoField"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T21:57:16.489115Z",
     "start_time": "2024-05-29T21:57:16.481797Z"
    }
   },
   "source": [
    "def filter_bandpass(signal, low_freq, high_freq, channels=None, method=\"iir\"):\n    \"\"\"Filter signal on specific channels and in a specific frequency band\"\"\"\n    sig = signal.copy()\n    if channels is not None:\n        sig.pick_channels(channels)\n    sig.filter(l_freq=low_freq, h_freq=high_freq, method=method, verbose=False)\n    return sig\n\n\ndef plot_detection(ax, rp_label, rpf_label):\n    labels = []\n    ylims = ax.get_ylim()\n    height = ylims[1] - ylims[0]\n    if not rp_label:\n        r1 = ax.axhspan(\n            ylims[0] + 0.06 * height, ylims[1] - 0.05 * height,\n            edgecolor='r', facecolor='none',\n            xmin=-test_time_start / test_duration - 0.005,\n            xmax=(duration - test_time_start) / test_duration - 0.005)\n        labels.append(r1)\n        ax.text(0.25, 0.95, 'RP', color='r', size=16, transform=ax.transAxes)\n    if not rpf_label:\n        r2 = ax.axhspan(\n            ylims[0] + 0.05 * height, ylims[1] - 0.06 * height,\n            edgecolor='m', facecolor='none',\n            xmin=-test_time_start / test_duration + 0.005,\n            xmax=(duration - test_time_start) / test_duration + 0.005)\n        labels.append(r2)\n        ax.text(0.65, 0.95, 'RPF', color='m', size=16, transform=ax.transAxes)\n    if rp_label and rpf_label:\n        r3 = ax.axhspan(\n            ylims[0] + 0.05 * height, ylims[1] - 0.05 * height,\n            edgecolor='k', facecolor='none',\n            xmin=-test_time_start / test_duration,\n            xmax=(duration - test_time_start) / test_duration)\n        labels.append(r3)\n    return labels"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EEG data\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T21:59:13.059028Z",
     "start_time": "2024-05-29T21:59:12.132322Z"
    }
   },
   "source": [
    "from filenames_and_paths import *\n",
    "import mne\n",
    "\n",
    "# Load motor imagery data\n",
    "# raw = read_raw_edf(eegbci.load_data(2, [5])[0], preload=True, verbose=False)\n",
    "raw = mne.io.read_raw_brainvision(folders.raw_data + path014 + filenames014[0] + '.vhdr', preload=True)\n",
    "eegbci.standardize(raw)\n",
    "raw.drop_channels([\"EOG\", \"BIP1\", ])\n",
    "raw.set_montage(make_standard_montage('standard_1020'))\n",
    "sfreq = int(raw.info['sfreq'])  # 160 Hz\n",
    "\n",
    "# Select the 21 channels of the 10-20 montage\n",
    "raw.pick_channels(\n",
    "    ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T7', 'C3', 'Cz', 'C4',\n",
    "     'T8', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'Oz', 'O2'], ordered=True)\n",
    "ch_names = raw.ch_names\n",
    "ch_count = len(ch_names)\n",
    "\n",
    "# Define time-series epoching with a sliding window\n",
    "duration = 2.5    # duration of epochs\n",
    "interval = 0.2    # interval between epochs"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riemannian potato\n\nRiemannian potato (RP) [2]_ selects all channels and filter between 1 and\n35 Hz.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T21:59:24.695511Z",
     "start_time": "2024-05-29T21:59:22.750246Z"
    }
   },
   "source": [
    "# RP definition\nz_th = 2.0           # z-score threshold\nlow_freq, high_freq = 1., 35.\nrp = Potato(metric='riemann', threshold=z_th)\n\n# EEG processing for RP\nrp_sig = filter_bandpass(raw, low_freq, high_freq)  # band-pass filter\nrp_epochs = make_fixed_length_epochs(  # epoch time-series\n    rp_sig, duration=duration, overlap=duration - interval, verbose=False\n).get_data(copy=False)\nrp_covs = Covariances(estimator='scm').transform(rp_epochs)\n\n# RP training\ntrain_covs = 45      # nb of matrices for training\ntrain_set = range(train_covs)\nrp.fit(rp_covs[train_set])"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riemannian potato field\n\nRiemannian potato field (RPF) [1]_ combines several potatoes of low\ndimensionality, each one designed to capture a different kind of artifact\ntypically affecting some specific spatial area (i.e. subsets of channels)\nand/or specific frequency bands.\n\nBCI or NFB applications aim at the modulation specific brain oscillations, it\nis thus advisable to exclude such frequencies from potatoes so as to prevent\ndesirable brain modulations to be detected as artifactual.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T21:59:44.104589Z",
     "start_time": "2024-05-29T21:59:40.784461Z"
    }
   },
   "source": [
    "# RPF definition\np_th = 0.01          # probability threshold\nrpf_config = {\n    'RPF eye_blinks': {  # for eye-blinks\n        'ch_names': ['Fp1', 'Fpz', 'Fp2'],\n        'low_freq': 1.,\n        'high_freq': 20.},\n    'RPF occipital': {  # for high-frequency artifacts in occipital area\n        'ch_names': ['O1', 'Oz', 'O2'],\n        'low_freq': 25.,\n        'high_freq': 45.,\n        'cov_normalization': 'trace'},  # trace-norm to be insensitive to power\n    'RPF global_lf': {  # for low-frequency artifacts in all channels\n        'ch_names': None,\n        'low_freq': 0.5,\n        'high_freq': 3.}\n}\nrpf = PotatoField(metric='riemann', z_threshold=z_th, p_threshold=p_th,\n                  n_potatoes=len(rpf_config))\n\n# EEG processing for RPF\nrpf_covs = []\nfor p in rpf_config.values():  # loop on potatoes\n    rpf_sig = filter_bandpass(raw, p.get('low_freq'), p.get('high_freq'),\n                              channels=p.get('ch_names'))\n    rpf_epochs = make_fixed_length_epochs(\n        rpf_sig, duration=duration, overlap=duration - interval, verbose=False\n    ).get_data(copy=False)\n    covs_ = Covariances(estimator='scm').transform(rpf_epochs)\n    if p.get('cov_normalization'):\n        covs_ = normalize(covs_, p.get('cov_normalization'))\n    rpf_covs.append(covs_)\n\n# RPF training\nrpf.fit([c[train_set] for c in rpf_covs])"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Artifact Detection with Potatoes\n\nDetect artifacts/outliers on test set, with an animation to imitate an online\nacquisition, processing and artifact detection of EEG time-series.\nRemark that all these potatoes are semi-dynamic: they are updated when EEG is\nnot artifacted [1]_.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T22:00:01.053321Z",
     "start_time": "2024-05-29T22:00:00.149007Z"
    }
   },
   "source": [
    "# Prepare data for online detection\ntest_covs_max = 400     # nb of epochs to visualize in this example\ntest_covs_visu = 100    # nb of z-scores/proba to display simultaneously\ntest_time_start = -2    # start time to display signal\ntest_time_end = 5       # end time to display signal\n\ntest_duration = test_time_end - test_time_start\ntime_start = train_covs * interval + test_time_start\ntime_end = train_covs * interval + test_time_end\ntime = np.linspace(time_start, time_end, int((time_end - time_start) * sfreq),\n                   endpoint=False)\nraw.filter(l_freq=0.5, h_freq=75., method='iir', verbose=False)\neeg_data = 1e5 * raw.get_data()\nsig = eeg_data[:, int(time_start * sfreq):int(time_end * sfreq)]\neeg_offset = - 15 * np.linspace(1, ch_count, ch_count, endpoint=False)\ncovs_t, covs_z = np.empty([0]), np.empty([len(rpf_config) + 1, 0])\ncovs_p = np.empty([0])\n\nfig, ax = plt.subplots(figsize=(12, 10), nrows=2, ncols=1)\nfig.suptitle('Online artifact detection, RP vs RPF', fontsize=16)\nax[0].set(xlabel='Time (s)', ylabel='EEG channels')\nax[0].set_xlim([time[0], time[-1]])\nax[0].set_yticks(eeg_offset)\nax[0].set_yticklabels(ch_names)\npl = ax[0].plot(time, sig.T + eeg_offset.T, lw=0.75)\nlabels = []\n\nax[1].set(xlabel='Time (s)', ylabel='Z-scores of distances to references')\npl2 = ax[1].plot(covs_t, covs_z.T, lw=0.75)\nfor c, l in enumerate(['RP'] + [*rpf_config]):\n    pl2[c].set_label(l)\nax[1].set_ylim([-1.5, 8.5])\nax[1].legend(loc='upper left')\naxp = ax[1].twinx()\naxp.set(ylabel='RPF probability of clean EEG')\npl3 = axp.plot(covs_t, covs_p, lw=0.75, c='k', label='RPF proba')\naxp.set_ylim([0, 1])\naxp.legend(loc='upper right')"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T22:00:18.648911Z",
     "start_time": "2024-05-29T22:00:18.640810Z"
    }
   },
   "source": [
    "# Prepare animation for online detection\ndef online_detect(t):\n    global time, sig, labels, covs_t, covs_z, covs_p\n\n    # Online artifact detection\n    rp_label = rp.predict(rp_covs[np.newaxis, t])[0]\n    rp_zscore = rp.transform(rp_covs[np.newaxis, t])\n    rpf_label = rpf.predict([c[np.newaxis, t] for c in rpf_covs])[0]\n    rpf_zscores = rpf.transform([c[np.newaxis, t] for c in rpf_covs])\n    rpf_proba = rpf.predict_proba([c[np.newaxis, t] for c in rpf_covs])\n    if rp_label == 1:\n        rp.partial_fit(rp_covs[np.newaxis, t], alpha=1 / t)\n    if rpf_label == 1:\n        rpf.partial_fit([c[np.newaxis, t] for c in rpf_covs], alpha=1 / t)\n\n    # Update data\n    time_start = t * interval + test_time_end\n    time_end = (t + 1) * interval + test_time_end\n    time_ = np.linspace(time_start, time_end, int(interval * sfreq),\n                        endpoint=False)\n    time = np.r_[time[int(interval * sfreq):], time_]\n    sig = np.hstack((sig[:, int(interval * sfreq):],\n                     eeg_data[:, int(time_start*sfreq):int(time_end*sfreq)]))\n    covs_t = np.r_[covs_t, time_start]\n    covs_z = np.hstack((covs_z,\n                        np.vstack((rp_zscore[np.newaxis], rpf_zscores.T))))\n    covs_p = np.r_[covs_p, rpf_proba]\n    if len(covs_p) > test_covs_visu:\n        covs_t, covs_z, covs_p = covs_t[1:], covs_z[:, 1:], covs_p[1:]\n\n    # Update plot\n    for c in range(ch_count):\n        pl[c].set_data(time, sig[c] + eeg_offset[c])\n        pl[c].axes.set_xlim(time[0], time[-1])\n    for lbl in labels:\n        lbl.remove()\n    for txt in ax[0].texts:\n        txt.set_visible(False)\n    labels = plot_detection(ax[0], rp_label, rpf_label)\n    for c in range(len(pl2)):\n        pl2[c].set_data(covs_t, covs_z[c])\n        pl2[c].axes.set_xlim(covs_t[0] - 0.1, covs_t[-1])\n    pl3[0].set_data(covs_t, covs_p)\n    return pl, pl2, pl3\n\n\ninterval_display = 1.0  # can be changed for a slower display\n\npotato = FuncAnimation(fig, online_detect,\n                       frames=range(train_covs, test_covs_max),\n                       interval=interval_display, blit=False, repeat=False)"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot online detection\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T22:00:21.121478Z",
     "start_time": "2024-05-29T22:00:20.377164Z"
    }
   },
   "source": [
    "# Plot complete visu: a dynamic display is required\nplt.show()\n\n# Plot only 10s, for animated documentation\ntry:\n    from IPython.display import HTML\nexcept ImportError:\n    raise ImportError(\"Install IPython to plot animation in documentation\")\n\nplt.rcParams[\"animation.embed_limit\"] = 10\nHTML(potato.to_jshtml(fps=5, default_mode='loop'))"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n.. [1] [The Riemannian Potato Field: A Tool for Online Signal Quality Index\n   of EEG](https://hal.archives-ouvertes.fr/hal-02015909)\n   Q. Barthélemy, L. Mayaud, D. Ojeda, and M. Congedo. IEEE Transactions\n   on Neural Systems and Rehabilitation Engineering, IEEE Institute of\n   Electrical and Electronics Engineers, 2019, 27 (2), pp.244-255\n.. [2] [The Riemannian Potato: an automatic and adaptive artifact detection\n   method for online experiments using Riemannian geometry](https://hal.archives-ouvertes.fr/hal-00781701)\n   A. Barachant, A Andreev, and M. Congedo. TOBI Workshop lV, Jan 2013, Sion,\n   Switzerland. pp.19-20.\n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
