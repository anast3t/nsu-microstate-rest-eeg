{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Импорты",
   "id": "b69407ff2e9534f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:43:28.775825Z",
     "start_time": "2024-05-03T19:43:27.295593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mne\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import os\n",
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "from typing import Self\n",
    "\n",
    "\n",
    "import pickle\n",
    "import typing\n",
    "import mne\n",
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "\n",
    "# from helper import MicrostateHelperWrapper as MSHW\n",
    "# from helper import Folders\n",
    "from filenames_and_paths import *"
   ],
   "id": "a1ab76955abdd454",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:43:28.797134Z",
     "start_time": "2024-05-03T19:43:28.776827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "class Folders:\n",
    "    \"\"\"\n",
    "    Class for storing the paths to the folders for the data.\n",
    "    ALL FOLDERS SHOULD END WITH A SLASH\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            end_folder: str,\n",
    "            raw_data: str,\n",
    "            preprocessed_data: str,\n",
    "            save_data: str,\n",
    "            statistics: str,\n",
    "            mhw_objects: str,\n",
    "            images: str\n",
    "    ):\n",
    "        self.end_folder = end_folder\n",
    "        self.raw_data = raw_data\n",
    "        self.preprocessed_data = preprocessed_data\n",
    "        self.save_data = save_data\n",
    "        self.statistics = statistics\n",
    "        self.mhw_objects = mhw_objects\n",
    "        self.images = images\n",
    "\n",
    "\n",
    "class MicrostateHelperWrapper:\n",
    "    def __init__(\n",
    "            self,\n",
    "            folders: Folders,\n",
    "            raw: mne.io.Raw,\n",
    "            raw_filename: str\n",
    "    ):\n",
    "        self.raw = raw\n",
    "        self.raw_filename = raw_filename\n",
    "        self.folders = folders\n",
    "        self.sampling_rate = raw.info['sfreq']\n",
    "        self.ms = None\n",
    "        self.splitted_ms = None\n",
    "        self.split_dynamic_statistics = None\n",
    "        self.split_static_statistics = None\n",
    "\n",
    "    def load(self) -> Self:\n",
    "        print(\"Loading MHW object\", self.raw_filename)\n",
    "        with open(\n",
    "                self.folders.save_data +\n",
    "                self.folders.mhw_objects +\n",
    "                self.folders.end_folder +\n",
    "                self.raw_filename + '.pkl',\n",
    "                'rb'\n",
    "        ) as file:\n",
    "            return pickle.load(file)\n",
    "\n",
    "    def save(self) -> Self:\n",
    "        print(\"Saving MHW object\", self.raw_filename)\n",
    "        folder = self.folders.save_data + self.folders.mhw_objects + self.folders.end_folder\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        with open(folder + self.raw_filename + '.pkl', 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        return self\n",
    "\n",
    "    def check_saved(self) -> bool:\n",
    "        try:\n",
    "            with open(\n",
    "                    self.folders.save_data +\n",
    "                    self.folders.mhw_objects +\n",
    "                    self.folders.end_folder +\n",
    "                    self.raw_filename + '.pkl',\n",
    "                    'rb'\n",
    "            ) as file:\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "\n",
    "    def split_ms_sequence(\n",
    "            self,\n",
    "            start_sample=0,\n",
    "            end_sample=0,\n",
    "            start_time=0,\n",
    "            time_end=0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Splits the sequence of a microstates object from a given start_sample to a given end_sample.\n",
    "        If time_end is set, it will convert the time to samples using the sampling_rate, ignoring passed samples.\n",
    "\n",
    "        :param start_sample: starting sample of the sequence\n",
    "        :param end_sample: ending sample of the sequence\n",
    "        :param start_time: starting time of the sequence\n",
    "        :param time_end: ending time of the sequence\n",
    "        :return: Microstates object with the sequence sliced from start to end\n",
    "        \"\"\"\n",
    "\n",
    "        sampling_rate = self.sampling_rate\n",
    "        ms_copy = self.ms.copy()\n",
    "\n",
    "        if time_end != 0 and end_sample != 0:\n",
    "            raise ValueError(\"Only one of time_end or end_sample should be set\")\n",
    "\n",
    "        if time_end != 0:\n",
    "            end_sample = int(time_end * sampling_rate)\n",
    "        if start_time != 0:\n",
    "            start_sample = int(start_time * sampling_rate)\n",
    "\n",
    "        ms_copy['Sequence'] = ms_copy['Sequence'][start_sample:end_sample]\n",
    "        ms_copy['GFP'] = ms_copy['GFP'][start_sample:end_sample]\n",
    "        return ms_copy\n",
    "\n",
    "    def apply_basic_switch_threshold(\n",
    "            self,\n",
    "            inplace=False,\n",
    "            threshold=0.02,\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Applies the basic switch threshold algorithm to the microstates sequence.\n",
    "        Removes \"noisy\" microstates that are shorter than the threshold.\n",
    "\n",
    "        :param threshold: threshold for the minimum duration (is seconds) of a microstate\n",
    "        :param inplace: if True, will apply the changes to the current microstates object\n",
    "        :return: Microstates object with the basic switch threshold applied\n",
    "        \"\"\"\n",
    "\n",
    "        sampling_rate = self.sampling_rate\n",
    "        ms_clone = self.ms.copy()\n",
    "\n",
    "        sequence = ms_clone['Sequence'].copy()\n",
    "        gfp = ms_clone['GFP']\n",
    "        threshold_samples = threshold * sampling_rate\n",
    "        print(\"Threshold samples\", threshold_samples)\n",
    "        while True:\n",
    "            while True:\n",
    "                intervals = []\n",
    "                candidates = []\n",
    "                for i in range(len(sequence) - 1):\n",
    "                    if sequence[i] != sequence[i + 1]:\n",
    "                        intervals.append((i, (i - intervals[-1][0] if len(intervals) > 0 else i), sequence[i - 1]))\n",
    "                intervals.append(\n",
    "                    (len(sequence) - 1, len(sequence) - 1 - intervals[-1][0], sequence[-1], (len(sequence) - 1) / 2048))\n",
    "                # print(np.array(intervals))\n",
    "                i = 1\n",
    "                while i < len(intervals) - 1:\n",
    "                    if (intervals[i][1] < threshold_samples) and (intervals[i - 1][2] == intervals[i + 1][2]):\n",
    "                        # length = intervals[i][1] + intervals[i-1][1] + intervals[i+1][1]\n",
    "                        candidates.append((intervals[i - 1], intervals[i], intervals[i + 1]))\n",
    "                        i += 2\n",
    "                    i += 1\n",
    "                if len(candidates) == 0:\n",
    "                    break\n",
    "                for candidate in candidates:\n",
    "                    start = candidate[0][0]\n",
    "                    end = candidate[1][0] + 1\n",
    "                    state = candidate[0][2]\n",
    "                    # print(\"Filling candidate\", start, end, state)\n",
    "                    # nk.microstates_plot(ms_clone, epoch = (start-50, end+50))\n",
    "                    sequence[start:end] = state\n",
    "                    # ms_clone['Sequence'] = sequence\n",
    "                    # nk.microstates_plot(ms_clone, epoch = (start-50, end+50))\n",
    "                # time.sleep(500)\n",
    "            # ms_clone['Sequence'] = sequence\n",
    "            # nk.microstates_plot(ms_clone, epoch = (0, int(2048)))\n",
    "            # print(\"Second stage candidates\")\n",
    "\n",
    "            # while True:\n",
    "            intervals = []\n",
    "            candidates = []\n",
    "            local_gfp_mean = 0\n",
    "            for i in range(len(sequence) - 1):\n",
    "                local_gfp_mean += gfp[i]\n",
    "                if sequence[i] != sequence[i + 1]:\n",
    "                    # print(\"Adding sequence\", i, \"State\", sequence[i], \"State\", sequence[i+1])\n",
    "                    length = (i - intervals[-1][0] if len(intervals) > 0 else i)\n",
    "                    if length == 0:\n",
    "                        length = 1\n",
    "                    state = sequence[i - 1]\n",
    "                    local_gfp_mean /= length\n",
    "                    intervals.append((i, length, state, local_gfp_mean))\n",
    "                    local_gfp_mean = 0\n",
    "            intervals.append((len(sequence) - 1, len(sequence) - 1 - intervals[-1][0], sequence[-1], 0))\n",
    "            # print(intervals)\n",
    "            i = 1\n",
    "            while i < len(intervals) - 1:\n",
    "                # print(\"Checking interval\", intervals[i], threshold_samples)\n",
    "                if intervals[i][1] < threshold_samples:\n",
    "                    # gfp_diff_l = intervals[i][3] - intervals[i-1][3]\n",
    "                    # gfp_diff_r = intervals[i][3] - intervals[i+1][3]\n",
    "                    # print(\"GFP diff\", gfp_diff_l, gfp_diff_r)\n",
    "                    ln_diff_l = (intervals[i][1] - intervals[i - 1][1])\n",
    "                    ln_diff_r = intervals[i][1] - intervals[i + 1][1]\n",
    "                    if ln_diff_l > 0 and ln_diff_r > 0:\n",
    "                        i += 1\n",
    "                        continue\n",
    "\n",
    "                    # gfp_diff_l = intervals[i][3] - intervals[i-1][3]\n",
    "                    # gfp_diff_r = intervals[i][3] - intervals[i+1][3]\n",
    "\n",
    "                    # print(\"LN diff\", ln_diff_l, ln_diff_r, intervals[i][1])\n",
    "\n",
    "                    # if gfp_diff_l > gfp_diff_r:\n",
    "                    if ln_diff_l < ln_diff_r:\n",
    "                        candidates.append((intervals[i - 1], intervals[i], intervals[i - 1][2]))\n",
    "                    else:\n",
    "                        candidates.append((intervals[i - 1], intervals[i], intervals[i + 1][2]))\n",
    "                    i += 2\n",
    "                i += 1\n",
    "            if len(candidates) == 0:\n",
    "                break\n",
    "            # start_min = 10000000\n",
    "            # end_max = 0\n",
    "            for candidate in candidates:\n",
    "                start = candidate[0][0]\n",
    "                # if start < start_min:\n",
    "                #     start_min = start\n",
    "                end = candidate[1][0] + 1\n",
    "                # if end > end_max:\n",
    "                #     end_max = end\n",
    "                state = candidate[2]\n",
    "                # print(\"Filling candidate\", start, end, state)\n",
    "                # nk.microstates_plot(ms_clone, epoch = (start-40, end+40))\n",
    "                sequence[start:end] = state\n",
    "                # ms_clone['Sequence'] = sequence\n",
    "                # nk.microstates_plot(ms_clone, epoch = (start-40, end+40))\n",
    "                # print('------')\n",
    "        # print(sequence[:100])\n",
    "        ms_clone['Sequence'] = sequence\n",
    "\n",
    "        print(\"Applied basic switch threshold\")\n",
    "\n",
    "        if inplace:\n",
    "            self.ms = ms_clone\n",
    "            return self\n",
    "        else:\n",
    "            full_copy = copy.deepcopy(self)\n",
    "            full_copy.ms = ms_clone\n",
    "            return full_copy\n",
    "\n",
    "    def get_event_bounds_by_event_transitions(\n",
    "            self,\n",
    "            key_names,\n",
    "            key_namings,\n",
    "            transitions,\n",
    "            time_threshold=20,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Extracts event bounds from the raw data annotations using the event transitions.\n",
    "        :param key_names: annotation names of the events to look for\n",
    "        :param key_namings: annotation names mapped to event meaning\n",
    "        :param transitions: event transitions to look for in format [[from_event_name, [to_event_names]]]\n",
    "        :param time_threshold: minimum duration of the event in seconds\n",
    "        :return:\n",
    "            (timestamps - [[start_sample, end_sample]],\n",
    "            events - [event_meaning_name],\n",
    "            event_names - {annotation_number: event_meaning_name})\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        raw = self.raw\n",
    "        sampling_rate = self.sampling_rate\n",
    "\n",
    "        def check_event_name(pair, key_names):\n",
    "            print(pair)\n",
    "            key, value = pair\n",
    "            for key_name in key_names:\n",
    "                if key_name in key:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        raw_events = mne.events_from_annotations(raw)\n",
    "        event_sequence = list(map(lambda x: [x[0], x[2]], raw_events[0]))\n",
    "        event_namemap = dict(filter(lambda x: check_event_name(x, key_names), raw_events[1].items()))\n",
    "        event_numbers = list(event_namemap.values())\n",
    "        threshold_samples = time_threshold * sampling_rate\n",
    "\n",
    "        def get_event_number(event_name, _ev_namemap):\n",
    "            return list(filter(lambda val: event_name in val[0], _ev_namemap.items()))[0]\n",
    "\n",
    "        def remap_transitions_to_numbers(trans, ev_namemap):\n",
    "            remapped_transitions = []\n",
    "            for transition in trans:\n",
    "                remapped_transitions.append(\n",
    "                    [get_event_number(transition[0], ev_namemap)[1],\n",
    "                     list(map(lambda x: get_event_number(x, ev_namemap)[1], transition[1]))]\n",
    "                )\n",
    "            return remapped_transitions\n",
    "\n",
    "        transition_numbers = remap_transitions_to_numbers(transitions, event_namemap)\n",
    "        filtered_sequence = list(filter(lambda x: x[1] in event_numbers, event_sequence))\n",
    "        timestamps = []\n",
    "        events = []\n",
    "        for idx in range(len(filtered_sequence)):\n",
    "            event = filtered_sequence[idx]\n",
    "            next_event = filtered_sequence[idx + 1] if idx + 1 < len(filtered_sequence) else None\n",
    "            # print(\"Idx\", idx, \"Event\", event, \"Next event\", next_event)\n",
    "            if next_event is None:\n",
    "                break\n",
    "            for transition in transition_numbers:\n",
    "                if (event[1] == transition[0]) and (next_event[1] in transition[1]):\n",
    "                    if threshold_samples > next_event[0] - event[0]:\n",
    "                        print(\"Event too short, skipping\", next_event[0] - event[0], event, next_event)\n",
    "                        break\n",
    "                    timestamps.append([event[0], next_event[0]])\n",
    "                    events.append(event[1])\n",
    "                    break\n",
    "        event_names = dict(map(lambda x: (get_event_number(x[0], event_namemap)[1], x[1]), key_namings.items()))\n",
    "        return timestamps, events, event_names\n",
    "\n",
    "    def split_ms_sequence_by_events(\n",
    "            self,\n",
    "            key_names,\n",
    "            key_namings,\n",
    "            transitions,\n",
    "            time_threshold=20,\n",
    "            recalc=False\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Splits the microstates sequence by the events in the raw data annotation. Sets in the splitted_ms attribute.\n",
    "\n",
    "        splitted_ms attribute =\n",
    "            (timestamps - [[start_sample, end_sample]],\n",
    "            events - [event_meaning_name],\n",
    "            event_names - {annotation_number: event_meaning_name})\n",
    "\n",
    "        :param key_names: annotation names of the events to look for\n",
    "        :param key_namings: annotation names mapped to event meaning\n",
    "        :param transitions: event transitions to look for in format [[from_event_name, [to_event_names]]]\n",
    "        :param time_threshold: minimum duration of the event in seconds\n",
    "        :param recalc: if True, will recalculate the split\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        if self.splitted_ms is not None and not recalc:\n",
    "            print('Already calculated microstates split')\n",
    "            return self\n",
    "        print('Calculating microstates split...')\n",
    "\n",
    "        timestamps, events, event_names = self.get_event_bounds_by_event_transitions(\n",
    "            key_names,\n",
    "            key_namings,\n",
    "            transitions,\n",
    "            time_threshold=time_threshold\n",
    "        )\n",
    "        sequences = []\n",
    "\n",
    "        for i in range(len(timestamps)):\n",
    "            ms_copy = self.split_ms_sequence(start_sample=timestamps[i][0], end_sample=timestamps[i][1])\n",
    "            sequences.append(ms_copy)\n",
    "\n",
    "        self.splitted_ms = (sequences, events, event_names, timestamps)\n",
    "\n",
    "        print(\"Splitted by events\")\n",
    "        return self\n",
    "\n",
    "    # TODO: params for the microstates_segment\n",
    "    def calc_raw_ms(\n",
    "            self,\n",
    "            recalc=False\n",
    "    ) -> Self:\n",
    "        \"\"\"\n",
    "        Calculates the microstates of the raw data. Sets the ms attribute. If recalc is False, will return the current\n",
    "        :param recalc: if True, will recalculate the microstates\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        if self.ms is not None and not recalc:\n",
    "            print('Already calculated microstates')\n",
    "            return self\n",
    "\n",
    "        print('Calculating microstates...')\n",
    "        microstates = nk.microstates_segment(\n",
    "            self.raw,\n",
    "            n_microstates=4,\n",
    "            method='kmod',\n",
    "            random_state=42,\n",
    "            optimize=True\n",
    "        )\n",
    "        self.ms = microstates\n",
    "\n",
    "        return self\n",
    "\n",
    "    def split_dynamic_calc_statistics(\n",
    "            self,\n",
    "            recalc=False\n",
    "    ) -> Self:\n",
    "\n",
    "        if self.split_dynamic_statistics is not None and not recalc:\n",
    "            print('Already calculated dynamic statistics')\n",
    "            return self\n",
    "\n",
    "        ms_sequences, events, event_names, timestamps = self.splitted_ms\n",
    "        dynamic = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(ms_sequences)):\n",
    "            print(\"Event: \", event_names[events[i]])\n",
    "            duration = (timestamps[i][1] - timestamps[i][0])\n",
    "            # nk.microstates_plot(ms_sequences[i], epoch = (0, duration))\n",
    "            # nk.microstates_static(ms_sequences[i], sampling_rate=sampling_rate, show=True)\n",
    "            ms_dynamic = nk.microstates_dynamic(ms_sequences[i], show=False)\n",
    "            ms_dynamic['Event'] = event_names[events[i]]\n",
    "            ms_dynamic['Order'] = i\n",
    "            dynamic = pd.concat([dynamic, ms_dynamic])\n",
    "\n",
    "        print(\"Calculated dynamic statistics\")\n",
    "        dynamic.reset_index(drop=True, inplace=True)\n",
    "        self.split_dynamic_statistics = dynamic\n",
    "        return self\n",
    "\n",
    "    def split_dynamic_save_statistics(self) -> Self:\n",
    "        folder = self.folders.save_data + self.folders.statistics + self.folders.end_folder\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        self.split_dynamic_statistics.to_csv(folder + self.raw_filename + '_split_dynamic_stats.csv', index=False)\n",
    "        print(\"Saved dynamic statistics\")\n",
    "        return self\n",
    "\n",
    "    def split_dynamic_drop_self_to_self(self) -> Self:\n",
    "        for i in range(4):\n",
    "            # print(f'Microstate_{i}_to_{i}')\n",
    "            if f'Microstate_{i}_to_{i}' in self.split_dynamic_statistics.columns:\n",
    "                self.split_dynamic_statistics.drop(f'Microstate_{i}_to_{i}', axis=1, inplace=True)\n",
    "            else:\n",
    "                print(f'Microstate_{i}_to_{i} not found or already dropped')\n",
    "        print(\"Dropped self-to-self transitions\")\n",
    "        return self\n",
    "\n",
    "    def split_static_calc_statistics(\n",
    "            self,\n",
    "            recalc=False\n",
    "    ) -> Self:\n",
    "\n",
    "        try:\n",
    "            if self.split_static_statistics is not None and not recalc:\n",
    "                print('Already calculated static statistics')\n",
    "                return self\n",
    "        except AttributeError:\n",
    "            self.split_static_statistics = None\n",
    "\n",
    "        ms_sequences, events, event_names, timestamps = self.splitted_ms\n",
    "        static = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(ms_sequences)):\n",
    "            print(\"Event: \", event_names[events[i]])\n",
    "            duration = (timestamps[i][1] - timestamps[i][0])\n",
    "            # nk.microstates_plot(ms_sequences[i], epoch = (0, duration))\n",
    "            ms_static = nk.microstates_static(ms_sequences[i], sampling_rate=self.sampling_rate, show=False)\n",
    "            ms_static['Event'] = event_names[events[i]]\n",
    "            ms_static['Order'] = i\n",
    "            static = pd.concat([static, ms_static])\n",
    "\n",
    "        print(\"Calculated static statistics\")\n",
    "        static.reset_index(drop=True, inplace=True)\n",
    "        self.split_static_statistics = static\n",
    "        return self\n",
    "\n",
    "    def split_static_save_statistics(self) -> Self:\n",
    "        folder = self.folders.save_data + self.folders.statistics + self.folders.end_folder\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        self.split_static_statistics.to_csv(folder + self.raw_filename + '_split_static_stats.csv', index=False, index_label=False)\n",
    "        print(\"Saved static statistics\")\n",
    "        return self\n"
   ],
   "id": "1d0a91e559052f1d",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Константы",
   "id": "738488099ec44583"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:43:28.803640Z",
     "start_time": "2024-05-03T19:43:28.797134Z"
    }
   },
   "cell_type": "code",
   "source": "# sampling_rate = 2048",
   "id": "a689485c41c74007",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MICROSTATES",
   "id": "2bea939f657dbbdb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculation of mean vals",
   "id": "1a95096b7788ab0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:43:28.808457Z",
     "start_time": "2024-05-03T19:43:28.803640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = filenames014[0]\n",
    "filepath = path014\n",
    "folders.end_folder = filepath"
   ],
   "id": "8d7b6ee2a7b6f3a9",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:43:31.478094Z",
     "start_time": "2024-05-03T19:43:30.115973Z"
    }
   },
   "cell_type": "code",
   "source": "raw: mne.io.Raw = mne.io.read_raw_eeglab(folders.preprocessed_data + folders.end_folder + filename + '.set')",
   "id": "448aa2681e0ba9bb",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:43:36.440278Z",
     "start_time": "2024-05-03T19:43:36.185754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mshw = MicrostateHelperWrapper(\n",
    "    raw = raw,\n",
    "    raw_filename = filename,\n",
    "    folders = folders\n",
    ")\n",
    "mshwt = MicrostateHelperWrapper(\n",
    "    raw = raw,\n",
    "    raw_filename = filename+'_th',\n",
    "    folders = folders\n",
    ")\n",
    "if mshwt.check_saved():\n",
    "    mshwt = mshwt.load()\n",
    "else:\n",
    "    if mshw.check_saved():\n",
    "        mshw = mshw.load()\n",
    "    else:\n",
    "        mshw.calc_raw_ms()\n",
    "    mshwt = mshw.apply_basic_switch_threshold(threshold=0.02, inplace=False)\n",
    "    mshwt.raw_filename = filename+'_th'\n",
    "    mshwt.save()"
   ],
   "id": "9340b81db299d4a9",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:43:38.851203Z",
     "start_time": "2024-05-03T19:43:38.354201Z"
    }
   },
   "cell_type": "code",
   "source": "nk.microstates_plot(mshwt.ms, epoch = (0, 2048*2))",
   "id": "6b217a3a45272582",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T10:50:40.434748Z",
     "start_time": "2024-05-01T10:50:40.432443Z"
    }
   },
   "cell_type": "code",
   "source": "# print(mshwt.ms['Sequence'], mshwt.ms['Microstates'])",
   "id": "9a7b6cfe7a69865f",
   "execution_count": 47,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T10:50:40.847504Z",
     "start_time": "2024-05-01T10:50:40.834886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nk.microstates_plot(mshwt.ms, epoch = (0, 2048*2))\n",
    "out2 = nk.microstates_classify(mshwt.ms[\"Sequence\"], mshwt.ms[\"Microstates\"])"
   ],
   "id": "3b8ae1040ed2553a",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T10:50:41.385376Z",
     "start_time": "2024-05-01T10:50:41.381425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ms = mshwt.ms.copy()\n",
    "ms['Sequence'] = out2[0]\n",
    "ms['Microstates'] = out2[1]"
   ],
   "id": "f2e098eac3e35a17",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T10:50:42.079448Z",
     "start_time": "2024-05-01T10:50:41.661825Z"
    }
   },
   "cell_type": "code",
   "source": "nk.microstates_plot(ms, epoch = (0, 2048*2))",
   "id": "6c389dacae5f7daa",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T10:50:44.119482Z",
     "start_time": "2024-05-01T10:50:44.117182Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8fca773406f0d17d",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:05:33.738141Z",
     "start_time": "2024-04-25T20:05:33.735682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nk.microstates_plot(mshw.ms, epoch = (0, 2048*2))\n",
    "# nk.microstates_plot(mshwt.ms, epoch = (0, 2048*2))\n",
    "# nk.microstates_static(mshw.ms, show=True)\n",
    "# nk.microstates_static(mshwt.ms, show=True)"
   ],
   "id": "cbf606515ea8d0d7",
   "execution_count": 102,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:05:33.745011Z",
     "start_time": "2024-04-25T20:05:33.739576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transitions = [['s11', ['s2', 's3', 's4']], ['s4', ['s2', 's3', 's11']]]\n",
    "# transitions = [['s11', ['s2', 's3']], ['s12', ['s2', 's3']]] # 14 - d1\n",
    "# transitions = [['s11', ['s3']], ['s12', ['s3']]] \n",
    "\n",
    "key_names = ['s11', 's2', 's3', 's4']\n",
    "# key_names = ['s11', 's12', 's2', 's3'] # 14 - d1\n",
    "# key_names = ['s11', 's12', 's3', 's1'] # 14 - d1\n",
    "\n",
    "key_namings = {'s11': \"Closed\", 's4': \"Opened\"}\n",
    "# key_namings = {'s11': \"Closed\", 's12': \"Opened\"}\n",
    "\n",
    "timestamps, events, event_names = mshw.get_event_bounds_by_event_transitions(key_names, key_namings, transitions)\n",
    "\n",
    "print(\"Timestamps\", timestamps)\n",
    "print(\"Events\", events)\n",
    "print(\"Event names\", event_names)\n",
    "\n",
    "if len(events) < 10:\n",
    "    raise ArithmeticError(\"Not enough events\")\n"
   ],
   "id": "7e74a6cd51e47538",
   "execution_count": 103,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:05:37.207695Z",
     "start_time": "2024-04-25T20:05:33.745846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mshw.split_ms_sequence_by_events(\n",
    "#     key_names = key_names,\n",
    "#     key_namings = key_namings,\n",
    "#     transitions = transitions\n",
    "# )\n",
    "(mshwt\n",
    "    .split_ms_sequence_by_events(\n",
    "        key_names = key_names,\n",
    "        key_namings = key_namings,\n",
    "        transitions = transitions\n",
    "    )\n",
    "    .split_dynamic_calc_statistics()\n",
    "    .split_dynamic_drop_self_to_self()\n",
    "    .split_dynamic_save_statistics()\n",
    "    .split_static_calc_statistics()\n",
    "    .split_static_save_statistics()\n",
    "    .save()\n",
    " )"
   ],
   "id": "96410ffdaf7c55ca",
   "execution_count": 104,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FOR ALL FILES IN ONE DATASET",
   "id": "4ee80aef577b7cdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:30:06.879755Z",
     "start_time": "2024-04-25T20:30:06.877259Z"
    }
   },
   "cell_type": "code",
   "source": "processed = []",
   "id": "c7e899db0e99b92c",
   "execution_count": 167,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T21:30:03.345836Z",
     "start_time": "2024-04-25T21:30:03.343627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exclude_from_event_check = [\n",
    "    \"INP0019_v1.5_REST3_Op005_Op007_08.12.23\",\n",
    "    \"INP0036_v1.5_REST1_Op005_Op010_12.12.23\",\n",
    "    \"INP0064_v1.5_rs22_Op009_A002_13.12.23\",\n",
    "    \"INP0064_v1.5_rs23_Op009_A002_13.12.23\"\n",
    "]"
   ],
   "id": "db449ecbf0cb4124",
   "execution_count": 190,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T21:30:07.934456Z",
     "start_time": "2024-04-25T21:30:03.675265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filenames = filenames064\n",
    "filepath = path064\n",
    "folders.end_folder = filepath\n",
    "for filename in filenames:\n",
    "    if filename in processed:\n",
    "        continue\n",
    "    raw: mne.io.Raw = mne.io.read_raw_eeglab(folders.preprocessed_data + folders.end_folder + filename + '.set')\n",
    "    mshw = MicrostateHelperWrapper(\n",
    "        raw = raw,\n",
    "        raw_filename = filename,\n",
    "        folders = folders\n",
    "    )\n",
    "    mshwt = MicrostateHelperWrapper(\n",
    "        raw = raw,\n",
    "        raw_filename = filename+'_th',\n",
    "        folders = folders\n",
    "    )\n",
    "    if mshwt.check_saved():\n",
    "        mshwt = mshwt.load()\n",
    "    else:\n",
    "        if mshw.check_saved():\n",
    "            mshw = mshw.load()\n",
    "        else:\n",
    "            mshw.calc_raw_ms()\n",
    "        mshwt = mshw.apply_basic_switch_threshold(threshold=0.02, inplace=False)\n",
    "        mshwt.raw_filename = filename+'_th'\n",
    "        mshwt.save()\n",
    "        \n",
    "    transitions = [['s11', ['s2', 's3', 's4']], ['s4', ['s2', 's3', 's11']]]\n",
    "    #transitions = [['s11', ['s2', 's3']], ['s12', ['s2', 's3']]] # 14 - d1\n",
    "    # transitions = [['s11', ['s3']], ['s12', ['s3']]]\n",
    "    \n",
    "    key_names = ['s11', 's2', 's3', 's4']\n",
    "    # key_names = ['s11', 's12', 's2', 's3'] # 14 - d1\n",
    "    # key_names = ['s11', 's12', 's3', 's1'] # 14 - d1\n",
    "    \n",
    "    key_namings = {'s11': \"Closed\", 's4': \"Opened\"}\n",
    "    # key_namings = {'s11': \"Closed\", 's12': \"Opened\"}\n",
    "    \n",
    "    timestamps, events, event_names = mshw.get_event_bounds_by_event_transitions(key_names, key_namings, transitions)\n",
    "    print(\"Timestamps\", timestamps)\n",
    "    print(\"Events\", events)\n",
    "    print(\"Event names\", event_names)\n",
    "    print(\"File length\", len(mshwt.ms['Sequence']) / mshwt.sampling_rate, \"seconds\", len(mshwt.ms['Sequence']), \"samples\")\n",
    "    if (len(events) < 10) and (filename not in exclude_from_event_check):\n",
    "        raise ArithmeticError(\"Not enough events\")\n",
    "    (mshwt\n",
    "        .split_ms_sequence_by_events(\n",
    "            key_names = key_names,\n",
    "            key_namings = key_namings,\n",
    "            transitions = transitions\n",
    "        )\n",
    "        .split_dynamic_calc_statistics()\n",
    "        .split_dynamic_drop_self_to_self()\n",
    "        .split_dynamic_save_statistics()\n",
    "        .split_static_calc_statistics()\n",
    "        .split_static_save_statistics()\n",
    "        .save()\n",
    "    )\n",
    "    mean = mshwt.split_static_statistics.groupby('Event').mean()\n",
    "    #bar\n",
    "    print('+++STATS+++')\n",
    "    ld = mean[filter(lambda x: '_LifetimeDistribution' in x, mshwt.split_static_statistics.columns)]\n",
    "    print(ld.loc['Opened'] - ld.loc['Closed'])\n",
    "    print('++++++++++++')\n",
    "    print('Done', filename)\n",
    "    print('------------------------------')\n",
    "    processed.append(filename)"
   ],
   "id": "44e6f6bf0acaac47",
   "execution_count": 191,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:28:18.160893Z",
     "start_time": "2024-04-25T20:28:18.009532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = mshwt.split_static_statistics.groupby('Event').mean()\n",
    "#bar\n",
    "ld = mean[filter(lambda x: '_LifetimeDistribution' in x, mshwt.split_static_statistics.columns)]\n",
    "(ld.loc['Opened'] - ld.loc['Closed']).plot(kind='bar')"
   ],
   "id": "6318f1b0ba61b449",
   "execution_count": 161,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T19:02:58.879564Z",
     "start_time": "2024-04-25T19:02:58.875023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proportions = mshw.split_static_statistics[filter(lambda x: 'Proportion' in x or 'Event' in x, mshw.split_static_statistics.columns)]\n",
    "proportions_th = mshwt.split_static_statistics[filter(lambda x: 'Proportion' in x or 'Event' in x, mshw.split_static_statistics.columns)]"
   ],
   "id": "92040192b0397eb3",
   "execution_count": 145,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T19:02:59.781647Z",
     "start_time": "2024-04-25T19:02:59.668389Z"
    }
   },
   "cell_type": "code",
   "source": "proportions.loc[proportions['Event'] == 'Closed'].plot()",
   "id": "2dc925321e350566",
   "execution_count": 146,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T19:03:01.319523Z",
     "start_time": "2024-04-25T19:03:01.209828Z"
    }
   },
   "cell_type": "code",
   "source": "proportions_th.loc[proportions_th['Event'] == 'Closed'].plot()",
   "id": "ca79bc28b09f0fa8",
   "execution_count": 147,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T19:01:17.752731Z",
     "start_time": "2024-04-25T19:01:17.603050Z"
    }
   },
   "cell_type": "code",
   "source": "proportions.loc[proportions['Event'] == 'Opened'].plot()",
   "id": "f402ef20b92ef0be",
   "execution_count": 132,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T19:01:19.974632Z",
     "start_time": "2024-04-25T19:01:19.487642Z"
    }
   },
   "cell_type": "code",
   "source": "proportions_th.loc[proportions_th['Event'] == 'Opened'].plot()",
   "id": "4ecb548875726ce1",
   "execution_count": 133,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mean_by_event(df):\n",
    "    clone = df.copy()\n",
    "    clone.drop('Order', axis=1, inplace=True)\n",
    "    return clone.groupby('Event').mean()"
   ],
   "id": "b687c2334cd13d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean = mean_by_event(mshw.split_dynamic_statistics)\n",
    "mean_th = mean_by_event(mshwt.split_dynamic_statistics)"
   ],
   "id": "8888e9319c724041",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean.T.plot()\n",
    "mean_th.T.plot()\n",
    "mean.to_csv('./save_data/ms_event_splited_statistics/dynamic/mean/'+filename+'_mean.csv')\n",
    "mean_th.to_csv('./save_data/ms_event_splited_statistics/dynamic/mean/'+filename+'_th_mean.csv')"
   ],
   "id": "a9b1221fb1ee716a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T18:28:22.914344Z",
     "start_time": "2024-04-25T18:28:22.903691Z"
    }
   },
   "cell_type": "code",
   "source": "mshwt.split_dynamic_statistics",
   "id": "ba3ba80eaf874199",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T19:50:30.522253Z",
     "start_time": "2024-04-21T19:50:30.520181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ms.plot_maps(maps, raw_bv_reconst_reref.info) \n",
    "# nk.microstates_plot(microstates, epoch = (0, 2048*10))\n",
    "# ms.plot_segmentation(segmentation[:2048], raw_bv_reconst_reref.get_data()[:, :2048], raw_bv_reconst_reref.times[:2048])\n",
    "# nk.microstates_static(microstates, sampling_rate=sampling_rate, show=True)\n",
    "# nk.microstates_dynamic(microstates, show=True)\n",
    "# gfp = nk.eeg_gfp(raw_resample)\n",
    "# \n",
    "# peaks = nk.microstates_peaks(raw_resample, gfp=gfp)\n",
    "# \n",
    "# # Plot the peaks in the first 200 data points\n",
    "# nk.events_plot(events = peaks[peaks < int(2048/2)], signal = gfp[0:int(2048/2)])"
   ],
   "id": "914e552cebb4fb89",
   "execution_count": 122,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
