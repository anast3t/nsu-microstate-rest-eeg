{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T11:32:07.238785Z",
     "start_time": "2024-05-18T11:32:06.142354Z"
    }
   },
   "source": [
    "import mne.io.eeglab.eeglab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functools\n",
    "from neurokit2.stats.cluster_quality import _cluster_quality_distance\n",
    "from filenames_and_paths import *\n",
    "from helper import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:32:07.247941Z",
     "start_time": "2024-05-18T11:32:07.239791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cluster_taahc(\n",
    "    data,\n",
    "    n_clusters=2,\n",
    "    gfp=None,\n",
    "    gfp_peaks=None,\n",
    "    gfp_sum_sq=None,\n",
    "    random_state=None,\n",
    "    use_peaks=False,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Atomize and Agglomerative Hierarchical Clustering Algorithm, AAHC (Murray et al., Brain Topography, 2008),\n",
    "    implemented by https://github.com/Frederic-vW/eeg_microstates/blob/master/eeg_microstates.py#L518\n",
    "\n",
    "    Preprocessing steps of GFP computation are necessary for the algorithm to run. If gfp arguments are specified,\n",
    "    data is assumed to have been filtered out based on gfp peaks (e.g., data[:, indices]), if not specified,\n",
    "    gfp indices will be calculated in the algorithm and data is assumed to be the full un-preprocessed input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Internal functions for aahc\n",
    "    def extract_row(A, k):\n",
    "        v = A[k, :]\n",
    "        A_ = np.vstack((A[:k, :], A[k + 1 :, :]))\n",
    "        return A_, v\n",
    "\n",
    "    def extract_item(A, k):\n",
    "        a = A[k]\n",
    "        A_ = A[:k] + A[k + 1 :]\n",
    "        return A_, a\n",
    "\n",
    "    def locmax(x):\n",
    "        \"\"\"Get local maxima of 1D-array\n",
    "        Args:\n",
    "            x: numeric sequence\n",
    "        Returns:\n",
    "            m: list, 1D-indices of local maxima\n",
    "        \"\"\"\n",
    "        dx = np.diff(x)  # discrete 1st derivative\n",
    "        zc = np.diff(np.sign(dx))  # zero-crossings of dx\n",
    "        m = 1 + np.where(zc == -2)[0]  # indices of local max.\n",
    "        return m\n",
    "\n",
    "    # Sanitize\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = np.array(data)\n",
    "    _, nch = data.shape\n",
    "\n",
    "    # If preprocessing is not Done already\n",
    "    if gfp is None and gfp_peaks is None and gfp_sum_sq is None:\n",
    "        gfp = data.std(axis=1)\n",
    "        gfp_peaks = locmax(gfp)\n",
    "        gfp_sum_sq = np.sum(gfp**2)  # normalizing constant in GEV\n",
    "        if use_peaks:\n",
    "            maps = data[gfp_peaks, :]  # initialize clusters\n",
    "            cluster_data = data[gfp_peaks, :]  # store original gfp peak indices\n",
    "        else:\n",
    "            maps = data.copy()\n",
    "            cluster_data = data.copy()\n",
    "    else:\n",
    "        maps = data.copy()\n",
    "        cluster_data = data.copy()\n",
    "\n",
    "    n_maps = maps.shape[0]\n",
    "\n",
    "    # cluster indices w.r.t. original size, normalized GFP peak data\n",
    "    Ci = [[k] for k in range(n_maps)]\n",
    "\n",
    "    # Main loop: atomize + agglomerate\n",
    "    while n_maps > n_clusters:\n",
    "\n",
    "        # correlations of the data sequence with each cluster\n",
    "        m_x, s_x = data.mean(axis=1, keepdims=True), data.std(axis=1)\n",
    "        m_y, s_y = maps.mean(axis=1, keepdims=True), maps.std(axis=1)\n",
    "        s_xy = 1.0 * nch * np.outer(s_x, s_y)\n",
    "        C = np.dot(data - m_x, np.transpose(maps - m_y)) / s_xy\n",
    "\n",
    "        # microstate sequence, ignore polarity\n",
    "        L = np.argmax(C**2, axis=1)\n",
    "\n",
    "        # GEV (global explained variance) of cluster k\n",
    "        gev = np.zeros(n_maps)\n",
    "        for k in range(n_maps):\n",
    "            r = L == k\n",
    "            gev[k] = np.sum(gfp[r] ** 2 * C[r, k] ** 2) / gfp_sum_sq\n",
    "\n",
    "        # merge cluster with the minimum GEV\n",
    "        imin = np.argmin(gev)\n",
    "\n",
    "        # N => N-1\n",
    "        maps, _ = extract_row(maps, imin)\n",
    "        Ci, reC = extract_item(Ci, imin)\n",
    "        re_cluster = []  # indices of updated clusters\n",
    "        for k in reC:  # map index to re-assign\n",
    "            c = cluster_data[k, :]\n",
    "            m_x, s_x = maps.mean(axis=1, keepdims=True), maps.std(axis=1)\n",
    "            m_y, s_y = c.mean(), c.std()\n",
    "            s_xy = 1.0 * nch * s_x * s_y\n",
    "            C = np.dot(maps - m_x, c - m_y) / s_xy\n",
    "            inew = np.argmax(C**2)  # ignore polarity\n",
    "            re_cluster.append(inew)\n",
    "            Ci[inew].append(k)\n",
    "        n_maps = len(Ci)\n",
    "\n",
    "        # Update clusters\n",
    "        re_cluster = list(set(re_cluster))  # unique list of updated clusters\n",
    "\n",
    "        # re-clustering by eigenvector method\n",
    "        for i in re_cluster:\n",
    "            idx = Ci[i]\n",
    "            Vt = cluster_data[idx, :]\n",
    "            Sk = np.dot(Vt.T, Vt)\n",
    "            evals, evecs = np.linalg.eig(Sk)\n",
    "            c = evecs[:, np.argmax(np.abs(evals))]\n",
    "            c = np.real(c)\n",
    "            maps[i] = c / np.sqrt(np.sum(c**2))\n",
    "\n",
    "    # Get distance\n",
    "    prediction = _cluster_quality_distance(cluster_data, maps, to_dataframe=True)\n",
    "    prediction[\"Cluster\"] = prediction.abs().idxmax(axis=1).values\n",
    "    prediction[\"Cluster\"] = [\n",
    "        np.where(prediction.columns == state)[0][0] for state in prediction[\"Cluster\"]\n",
    "    ]\n",
    "\n",
    "    # Function\n",
    "    clustering_function = functools.partial(\n",
    "        cluster_taahc, n_clusters=n_clusters, random_state=random_state, **kwargs\n",
    "    )\n",
    "\n",
    "    # Info dump\n",
    "    info = {\n",
    "        \"n_clusters\": n_clusters,\n",
    "        \"clustering_function\": clustering_function,\n",
    "        \"random_state\": random_state,\n",
    "    }\n",
    "\n",
    "    return prediction, maps, info"
   ],
   "id": "719f2aa6abd42335",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:32:07.449654Z",
     "start_time": "2024-05-18T11:32:07.248949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folders.end_folder = path014\n",
    "mhw: MicrostateHelperWrapper = MicrostateHelperWrapper.static_load(folders=folders, raw_filename=filenames014[0]+\"_th\")"
   ],
   "id": "a570a9368e9d54b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MHW object ACP_INP0014_REST1_1pnt_1vis_th\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:32:07.452655Z",
     "start_time": "2024-05-18T11:32:07.449654Z"
    }
   },
   "cell_type": "code",
   "source": "raw: mne.io.eeglab.eeglab.RawEEGLAB = mhw.raw",
   "id": "beb6645e354a6e0b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:33:41.758201Z",
     "start_time": "2024-05-18T11:33:41.602360Z"
    }
   },
   "cell_type": "code",
   "source": "data = raw.get_data()",
   "id": "9642440a994451bd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T11:33:44.587817Z",
     "start_time": "2024-05-18T11:33:42.243402Z"
    }
   },
   "cell_type": "code",
   "source": "cluster_taahc(data)",
   "id": "8f3456dc8ee962ba",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.47 TiB for an array with shape (1013447, 1013447) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mcluster_taahc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 110\u001B[0m, in \u001B[0;36mcluster_taahc\u001B[1;34m(data, n_clusters, gfp, gfp_peaks, gfp_sum_sq, random_state, use_peaks, **kwargs)\u001B[0m\n\u001B[0;32m    108\u001B[0m idx \u001B[38;5;241m=\u001B[39m Ci[i]\n\u001B[0;32m    109\u001B[0m Vt \u001B[38;5;241m=\u001B[39m cluster_data[idx, :]\n\u001B[1;32m--> 110\u001B[0m Sk \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mVt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mVt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    111\u001B[0m evals, evecs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39meig(Sk)\n\u001B[0;32m    112\u001B[0m c \u001B[38;5;241m=\u001B[39m evecs[:, np\u001B[38;5;241m.\u001B[39margmax(np\u001B[38;5;241m.\u001B[39mabs(evals))]\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 7.47 TiB for an array with shape (1013447, 1013447) and data type float64"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c04017d78adb4192"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
